{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfKUnU3kiykV",
        "outputId": "d5c5c7b9-bb86-4e51-f359-7a1b7f92bb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKTMnEWRiyhk",
        "outputId": "7d050dd0-d6c1-4c5a-b3da-2f0cdef63110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mia/csci566/project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Mia/csci566/project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BvwjJVo_L_D",
        "outputId": "4da8d6c8-c437-42d0-b475-9b61690a6058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mia/csci566/project/readmission\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Mia/csci566/project/readmission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading and preprocessing"
      ],
      "metadata": {
        "id": "LubAmuCS_T3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26CALsIqn09j"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "import pandas as pd\n",
        "import os\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score, accuracy_score,roc_auc_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJaRzkZUpC-6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('1_train_listfile801010.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pql8erJkp-ec",
        "outputId": "949f69d6-955a-4e3a-e1cb-ecd4f8b9e333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   stay  period_length  y_true\n",
            "0      88091_279924_episode1_timeseries_readmission.csv        29.0328       1\n",
            "1      14019_295689_episode1_timeseries_readmission.csv       691.0824       0\n",
            "2      23847_261301_episode1_timeseries_readmission.csv        33.6120       0\n",
            "3      78522_287059_episode1_timeseries_readmission.csv       312.6312       1\n",
            "4      83932_277793_episode2_timeseries_readmission.csv        24.1512       0\n",
            "...                                                 ...            ...     ...\n",
            "29863  89097_288765_episode1_timeseries_readmission.csv        27.5832       0\n",
            "29864  29050_255508_episode1_timeseries_readmission.csv        40.2720       0\n",
            "29865  31196_236381_episode1_timeseries_readmission.csv        42.1992       0\n",
            "29866  48233_267174_episode2_timeseries_readmission.csv        22.8960       0\n",
            "29867  31175_265786_episode1_timeseries_readmission.csv        92.4480       0\n",
            "\n",
            "[29868 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf6_8ROF4Hue",
        "outputId": "f80e899d-28e5-48ab-e942-7c70e7e65360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "os.path.exists('78522_287059_episode1_timeseries_readmission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL14ctXL2HNc"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('78522_287059_episode1_timeseries_readmission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmEKKTnqDj_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8263519f-b1ac-4246-e507-01972cc11efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([436, 15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-d967f730c368>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2[col] = df2[col].fillna(method='ffill').fillna(method='bfill').fillna(value=0)\n"
          ]
        }
      ],
      "source": [
        "numeric_cols = ['Hours', 'Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen',\\\n",
        "            'Glascow coma scale total', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure',\\\n",
        "            'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature',\\\n",
        "            'Weight', 'pH']\n",
        "df2 = df2[numeric_cols]\n",
        "for col in numeric_cols:\n",
        "    df2[col] = df2[col].fillna(method='ffill').fillna(method='bfill').fillna(value=0)\n",
        "df2_tensor = torch.tensor(df2.values)\n",
        "# print(df2.head(10))\n",
        "print(df2_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfmtZchMAmcS",
        "outputId": "3175ac85-90ce-4e72-d454-3b93b02b7a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3200, 3)\n"
          ]
        }
      ],
      "source": [
        "df_train = df[:3200]\n",
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LDXHarVBQM3"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    \"\"\"An abstract class representing a Dataset.\n",
        "    All other datasets should subclass it. All subclasses should override\n",
        "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
        "    supporting integer indexing in range from 0 to len(self) exclusive.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2vlVrkVBS5m"
      },
      "outputs": [],
      "source": [
        "class TrainData(Dataset):\n",
        "    \n",
        "    def __init__(self, data, labels):\n",
        "        # padding\n",
        "        self.data = pad_sequence(data, batch_first=True)[:,0:7680]\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        input = self.data[index]\n",
        "        label = self.labels[index]\n",
        "        return input, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-AJjP-dCvVl"
      },
      "outputs": [],
      "source": [
        "def prepare_data(input):\n",
        "    df = pd.read_csv(str(input['stay']))\n",
        "    # only choose numeric-valued features\n",
        "    numeric_cols = ['Hours', 'Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen',\\\n",
        "            'Glascow coma scale total', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure',\\\n",
        "            'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature',\\\n",
        "            'Weight', 'pH']\n",
        "    df = df[numeric_cols]\n",
        "    for col in numeric_cols:\n",
        "        # fill missing data\n",
        "        df[col] = df[col].fillna(method='ffill').fillna(method='bfill').fillna(value=0)\n",
        "    df_tensor = torch.tensor(df.values).reshape(-1)\n",
        "    return df_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDSkgLTEB_Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b809304-a26f-415f-a53c-b70e0a0b6e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-c381c8b1c019>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train['tensor'] = df_train.apply(prepare_data, axis=1)\n"
          ]
        }
      ],
      "source": [
        "# input size: 1000, runtime: ~6 min\n",
        "df_train['tensor'] = df_train.apply(prepare_data, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['tensor'][0]"
      ],
      "metadata": {
        "id": "3aH9jRDdhayx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7389b6d5-a6d6-47b8-99b3-c61d5d8504fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 12.5000,   0.0000,  40.0000,   0.0000,   0.0000, 105.0000,  78.0000,\n",
              "          0.0000,  54.0000,  94.0000,  18.0000, 100.0000,  36.4444,  51.7095,\n",
              "          7.0000,  15.0000,   0.0000,  40.0000,   0.0000,   0.0000, 105.0000,\n",
              "         78.0000,   0.0000,  54.0000,  94.0000,  18.0000, 100.0000,  36.4444,\n",
              "         51.7095,   7.0000,  17.3167,   0.0000,  40.0000,   0.0000,   0.0000,\n",
              "        105.0000,  78.0000,   0.0000,  54.0000,  94.0000,  18.0000, 100.0000,\n",
              "         36.4444,  51.7095,   7.0000,  17.3333,   0.0000,  40.0000,   0.0000,\n",
              "          0.0000, 105.0000,  78.0000,   0.0000,  54.0000,  94.0000,  18.0000,\n",
              "        100.0000,  36.4444,  51.7095,   7.0000,  17.3500,   0.0000,  40.0000,\n",
              "          0.0000,   0.0000, 105.0000,  78.0000,   0.0000,  54.0000,  94.0000,\n",
              "         18.0000, 100.0000,  36.4444,  51.7095,   7.0000,  17.3667,   0.0000,\n",
              "         40.0000,   0.0000,   0.0000, 105.0000,  78.0000,   0.0000,  54.0000,\n",
              "         94.0000,  18.0000, 100.0000,  36.4444,  51.7095,   7.0000,  17.6667,\n",
              "          0.0000,  40.0000,   0.0000,   0.0000, 105.0000,  76.0000,   0.0000,\n",
              "         54.0000,  94.0000,  18.0000, 100.0000,  36.4444,  51.7095,   7.0000,\n",
              "         17.6833,   0.0000,  40.0000,   0.0000,   0.0000, 105.0000,  76.0000,\n",
              "          0.0000,  54.0000,  94.0000,  18.0000, 100.0000,  36.4444,  51.7095,\n",
              "          7.0000,  17.7000,   0.0000,  40.0000,   0.0000,   0.0000, 105.0000,\n",
              "         76.0000,   0.0000,  54.0000,  94.0000,  18.0000, 100.0000,  36.4444,\n",
              "         51.8000,   7.0000,  17.9000,   0.0000,  40.0000,   0.0000,   0.0000,\n",
              "        105.0000,  76.0000,   0.0000,  54.0000,  94.0000,  18.0000, 100.0000,\n",
              "         36.4444,  51.8000,   7.0000,  18.0000,   0.0000,  43.0000,   0.0000,\n",
              "          0.0000, 105.0000,  76.0000,   0.0000,  54.0000,  95.0000,  18.0000,\n",
              "         91.0000,  36.4444,  51.8000,   7.0000,  19.0000,   0.0000,  43.0000,\n",
              "          0.0000,   0.0000, 105.0000,  74.0000,   0.0000,  53.0000,  97.0000,\n",
              "         19.0000,  81.0000,  36.4444,  51.8000,   7.0000,  20.0000,   0.0000,\n",
              "         41.0000,   0.0000,   0.0000, 105.0000,  77.0000,   0.0000,  56.0000,\n",
              "         97.0000,  18.0000, 100.0000,  35.8889,  51.8000,   7.0000,  21.0000,\n",
              "          0.0000,  44.0000,   0.0000,   0.0000, 105.0000,  79.0000,   0.0000,\n",
              "         58.0000,  94.0000,  20.0000, 102.0000,  35.8889,  51.8000,   7.0000,\n",
              "         22.0000,   0.0000,  39.0000,   0.0000,   0.0000, 105.0000,  78.0000,\n",
              "          0.0000,  56.0000,  96.0000,  18.0000, 109.0000,  35.8889,  51.8000,\n",
              "          7.0000,  23.0000,   0.0000,  51.0000,   0.0000,   0.0000, 105.0000,\n",
              "         87.0000,   0.0000,  66.0000,  98.0000,  20.0000, 107.0000,  35.8889,\n",
              "         51.8000,   7.0000,  24.0000,   0.0000,  51.0000,   0.0000,   0.0000,\n",
              "        105.0000,  94.0000,   0.0000,  69.0000,  95.0000,  20.0000, 107.0000,\n",
              "         37.5556,  51.8000,   7.0000,  24.2333,   0.0000,  45.0000,   0.0000,\n",
              "          0.0000, 105.0000,  94.0000,   0.0000,  69.0000,  95.0000,  20.0000,\n",
              "        116.0000,  37.5556,  51.8000,   7.0000,  25.0000,   0.0000,  45.0000,\n",
              "          0.0000,   0.0000, 105.0000,  96.0000,   0.0000,  69.0000,  95.0000,\n",
              "         20.0000, 116.0000,  37.5556,  51.8000,   7.0000,  25.0333,   0.0000,\n",
              "         37.0000,   0.0000,   0.0000, 105.0000,  96.0000,   0.0000,  59.0000,\n",
              "         95.0000,  20.0000, 120.0000,  37.5556,  51.8000,   7.0000,  26.0000,\n",
              "          0.0000,  38.0000,   0.0000,   0.0000, 105.0000,  86.0000,   0.0000,\n",
              "         57.0000,  96.0000,  19.0000, 107.0000,  37.5556,  51.8000,   7.0000,\n",
              "         26.9333,   0.0000,  38.0000,   0.0000,   0.0000,  94.0000,  86.0000,\n",
              "          0.0000,  57.0000,  96.0000,  19.0000, 107.0000,  37.5556,  51.8000,\n",
              "          7.0000,  27.0000,   0.0000,  41.0000,   0.0000,   0.0000,  94.0000,\n",
              "         80.0000,   0.0000,  58.0000,  96.0000,  18.0000, 107.0000,  37.5556,\n",
              "         51.8000,   7.0000,  27.9333,   0.0000,  41.0000,   0.0000,   0.0000,\n",
              "         94.0000,  80.0000,   0.0000,  58.0000,  96.0000,  18.0000, 107.0000,\n",
              "         37.5556,  51.8000,   7.0000,  28.0000,   0.0000,  45.0000,   0.0000,\n",
              "          0.0000,  94.0000,  88.0000,   0.0000,  64.0000,  97.0000,  23.0000,\n",
              "        126.0000,  37.2778,  51.8000,   7.0000,  29.0000,   0.0000,  39.0000,\n",
              "          0.0000,   0.0000,  94.0000,  86.0000,   0.0000,  61.0000,  98.0000,\n",
              "         42.0000, 121.0000,  37.2778,  51.8000,   7.0000], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMyvJ6ueQgIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49a4b25-bdef-4c29-fb6e-4637461546c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-1b311d9db4a9>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['tensor'] = df_test.apply(prepare_data, axis=1)\n"
          ]
        }
      ],
      "source": [
        "df_test = df[5000:5320]\n",
        "df_test['tensor'] = df_test.apply(prepare_data, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "h334-pIo_PvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "mBeHxqZCIGO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLpb8i-6_-VM"
      },
      "outputs": [],
      "source": [
        "data_vectors_train = df_train['tensor'].values\n",
        "labels_train = df_train['y_true'].values\n",
        "\n",
        "data_vectors_test = df_test['tensor'].values\n",
        "labels_test = df_test['y_true'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TrainData(data_vectors_train, labels_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=32)\n",
        "\n",
        "test_data = TrainData(data_vectors_test, labels_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=32)"
      ],
      "metadata": {
        "id": "rM3TbzBPM-GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data, target in test_loader:\n",
        "            print(data)\n",
        "            print(target)"
      ],
      "metadata": {
        "id": "Q1e6JIHnD1Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5beb390-3514-4300-98c3-e7aebc8ff309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11.0000,  0.0000, 60.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [10.1500,  0.0000, 62.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 7.7000,  0.0000, 47.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 1.2500,  0.0000, 89.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [13.3000,  0.0000, 75.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 6.4000,  0.0000, 62.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0])\n",
            "tensor([[ 22.0000,   0.0000,  78.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [ 10.8333,   0.0000,  74.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  9.0000,   0.0000,  59.0000,  ...,  37.6111, 124.1000,   5.0000],\n",
            "        ...,\n",
            "        [ 10.5000,   0.0000,  62.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  7.9333,   0.0000,  66.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [ 14.5833,   0.0000,  60.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 1, 0, 0, 0])\n",
            "tensor([[18.5000,  0.0000, 84.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [10.4833,  0.0000, 51.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [11.5000,  0.0000, 74.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 7.3333,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [17.8333,  0.0000, 49.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 5.9167,  0.0000, 95.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[14.9000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [17.2500,  0.0000, 73.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 4.3167,  0.0000, 46.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 6.5167,  0.0000, 55.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [12.6667,  0.0000, 59.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 3.4167,  0.0000, 56.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[16.7000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 4.9167,  0.0000, 60.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 6.4167,  0.0000, 49.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [19.2667,  0.0000, 78.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.7500,  0.0000, 75.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 9.0500,  0.0000, 77.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[ 4.0000,  0.0000, 59.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 5.6667,  0.0000, 33.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, 75.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 1.7500,  0.0000, 84.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [12.3833,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [13.8333,  0.0000, 24.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[ 7.4167,  0.0000, 49.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [18.2667,  0.0000, 74.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 8.2500,  0.0000, 51.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [17.2500,  0.0000, 62.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 93.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, 83.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0])\n",
            "tensor([[ 8.3500,  0.0000, 60.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [19.3333,  0.0000, 69.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [20.0000,  0.0000, 78.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 1.2500,  0.0000, 68.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [17.0000,  0.0000, 88.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [16.5667,  0.0000, 70.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[  9.0000,   0.0000,  48.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  2.3167,   0.0000,  85.0000,  ...,  37.2222, 104.5000,   7.4300],\n",
            "        [  4.5833,   0.0000,  77.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        ...,\n",
            "        [  8.1000,   0.0000,  69.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  4.0000,   0.0000,  57.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
            "        [  7.9167,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1])\n",
            "tensor([[ 8.2000,  0.0000, 47.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.2500,  0.0000, 51.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 2.6167,  0.0000, 89.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [11.0000,  0.0000, 43.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [10.0000,  0.0000, 49.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 2.0000,  0.0000, 51.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
            "        0, 0, 1, 0, 0, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre(predictions):\n",
        "    results = []\n",
        "    for i in predictions:\n",
        "        if i<0.5:\n",
        "            results.append(0)\n",
        "        else:\n",
        "            results.append(1)\n",
        "    return torch.Tensor(results)"
      ],
      "metadata": {
        "id": "U8EoxFWrERXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M5AwgA7Rr_4"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Model, self).__init__()\n",
        "        #Defining the layers\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(256, output_size)\n",
        "        self.act3 = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.float()\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO5Gp0tsUkwI"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, lr, weight_decay, n_epochs, batch_size):\n",
        "    # Define Loss, Optimizer\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # initialize tracker for max test f1 score\n",
        "    test_f1_max = 0.0 \n",
        "\n",
        "    # Training Run\n",
        "    model.train() # prep model for training\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # model.train() # prep model for training\n",
        "        train_loss = 0.0\n",
        "        test_loss = 0.0\n",
        "        num_samples_train = 0\n",
        "        num_samples_test = 0\n",
        "\n",
        "        for data, target in train_loader:\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data).reshape(-1)#.detach()\n",
        "            output = output.to(torch.float)\n",
        "            target = target.to(torch.float)\n",
        "\n",
        "            # print(output)\n",
        "            # print(target)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # loss = F.binary_cross_entropy(output.squeeze(), target)\n",
        "            # print(output)\n",
        "            # print(target)\n",
        "          \n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "            num_samples_train += data.size(0)\n",
        "\n",
        "        model.eval() # prep model for evaluation\n",
        "        for data, target in test_loader:\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data).reshape(-1)#.detach()\n",
        "            output = output.to(torch.float)\n",
        "            target = target.to(torch.float)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # loss = F.binary_cross_entropy(output.squeeze(), target)\n",
        "            # update running test loss \n",
        "            test_loss += loss.item()*data.size(0)\n",
        "            num_samples_test += data.size(0)\n",
        "\n",
        "        train_loss /= num_samples_train\n",
        "        test_loss /= num_samples_test\n",
        "        with torch.no_grad():\n",
        "            y_train_pred = torch.tensor([])\n",
        "            y_train_true = torch.tensor([])\n",
        "            y_train_score = torch.tensor([])\n",
        "            for data, target in train_loader:\n",
        "                output = model(data)\n",
        "                # _, pred_batch = output.max(1)\n",
        "                # print(output)\n",
        "                score_batch = output\n",
        "                # _, pred_batch = output.max(1)\n",
        "                pred_batch = pre(output)\n",
        "                y_train_pred = torch.cat((y_train_pred, pred_batch))\n",
        "                y_train_score = torch.cat((y_train_score, score_batch))\n",
        "                y_train_true = torch.cat((y_train_true, target))\n",
        "            y_train_pred = np.array(y_train_pred)\n",
        "            acc_train = accuracy_score(y_train_true, y_train_pred)\n",
        "            f1_train = f1_score(y_train_true, y_train_pred, average='macro')\n",
        "            auc_train = roc_auc_score(y_train_true, y_train_score)\n",
        "\n",
        "            y_test_pred = torch.tensor([])\n",
        "            y_test_true = torch.tensor([])\n",
        "            y_test_score = torch.tensor([])\n",
        "            for data, target in test_loader:\n",
        "                output = model(data)\n",
        "                # _, pred_batch = output.max(1)\n",
        "                score_batch = output\n",
        "                pred_batch = pre(output)\n",
        "                _, pred_batch = output.max(1)\n",
        "                y_test_pred = torch.cat((y_test_pred, pred_batch))\n",
        "                y_test_score = torch.cat((y_test_score, score_batch))\n",
        "                y_test_true = torch.cat((y_test_true, target))\n",
        "            y_test_pred = np.array(y_test_pred)\n",
        "            acc_test = accuracy_score(y_test_true, y_test_pred)\n",
        "            f1_test = f1_score(y_test_true, y_test_pred, average='macro')\n",
        "            auc_test = roc_auc_score(y_test_true, y_test_score)\n",
        "        print()\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTraining acc: {:.6f} \\tTest acc: {:.6f}\\tTraining f1: {:.6f} \\tTest f1: {:.6f}\\tTraining auc: {:.6f} \\tTest auc: {:.6f}'.format(\n",
        "          epoch+1, \n",
        "          train_loss,\n",
        "          test_loss,\n",
        "          acc_train,\n",
        "          acc_test,\n",
        "          f1_train,\n",
        "          f1_test,\n",
        "          auc_train,\n",
        "          auc_test\n",
        "          ))\n",
        "        \n",
        "      #  # save model if test f1 score has decreased\n",
        "      #   if f1_test >= test_f1_max:\n",
        "      #       print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "      #         test_f1_max,\n",
        "      #         f1_test))\n",
        "      #       torch.save(model.state_dict(), 'model.pt')\n",
        "      #       test_f1_max = f1_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw57BKCvRr8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb38557-95c3-4c93-e403-11e6a103671a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:50,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 \tTraining Loss: 0.942517 \tTest Loss: 0.945596 \tTraining acc: 0.846250 \tTest acc: 0.868750\tTraining f1: 0.499094 \tTest f1: 0.464883\tTraining auc: 0.519027 \tTest auc: 0.470880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:05<00:50,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 \tTraining Loss: 0.787756 \tTest Loss: 0.646966 \tTraining acc: 0.820937 \tTest acc: 0.868750\tTraining f1: 0.561705 \tTest f1: 0.464883\tTraining auc: 0.609804 \tTest auc: 0.497259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:08<00:45,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3 \tTraining Loss: 0.573468 \tTest Loss: 0.596653 \tTraining acc: 0.857187 \tTest acc: 0.868750\tTraining f1: 0.597130 \tTest f1: 0.464883\tTraining auc: 0.659351 \tTest auc: 0.461631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:10<00:42,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4 \tTraining Loss: 0.548516 \tTest Loss: 0.656960 \tTraining acc: 0.839375 \tTest acc: 0.868750\tTraining f1: 0.618013 \tTest f1: 0.464883\tTraining auc: 0.684203 \tTest auc: 0.522097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:13<00:41,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5 \tTraining Loss: 0.559587 \tTest Loss: 0.743799 \tTraining acc: 0.872500 \tTest acc: 0.868750\tTraining f1: 0.566916 \tTest f1: 0.464883\tTraining auc: 0.642456 \tTest auc: 0.461374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:16<00:36,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 \tTraining Loss: 0.509117 \tTest Loss: 0.626390 \tTraining acc: 0.871563 \tTest acc: 0.868750\tTraining f1: 0.614563 \tTest f1: 0.464883\tTraining auc: 0.729121 \tTest auc: 0.486725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:19<00:39,  3.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 \tTraining Loss: 0.489955 \tTest Loss: 0.838607 \tTraining acc: 0.778438 \tTest acc: 0.868750\tTraining f1: 0.602478 \tTest f1: 0.464883\tTraining auc: 0.717921 \tTest auc: 0.526465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:22<00:33,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 \tTraining Loss: 0.489590 \tTest Loss: 0.657670 \tTraining acc: 0.883750 \tTest acc: 0.868750\tTraining f1: 0.581081 \tTest f1: 0.464883\tTraining auc: 0.738806 \tTest auc: 0.470538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:25<00:31,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 9 \tTraining Loss: 0.471825 \tTest Loss: 0.574042 \tTraining acc: 0.870000 \tTest acc: 0.868750\tTraining f1: 0.608072 \tTest f1: 0.464883\tTraining auc: 0.732729 \tTest auc: 0.598664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:27<00:27,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10 \tTraining Loss: 0.499918 \tTest Loss: 0.692419 \tTraining acc: 0.886250 \tTest acc: 0.868750\tTraining f1: 0.600763 \tTest f1: 0.464883\tTraining auc: 0.742753 \tTest auc: 0.483128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:31<00:27,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 11 \tTraining Loss: 0.453352 \tTest Loss: 0.650711 \tTraining acc: 0.862187 \tTest acc: 0.868750\tTraining f1: 0.640443 \tTest f1: 0.464883\tTraining auc: 0.754138 \tTest auc: 0.489037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:34<00:24,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 12 \tTraining Loss: 0.434795 \tTest Loss: 0.759300 \tTraining acc: 0.877500 \tTest acc: 0.868750\tTraining f1: 0.580908 \tTest f1: 0.464883\tTraining auc: 0.749440 \tTest auc: 0.489637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:37<00:20,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 13 \tTraining Loss: 0.407028 \tTest Loss: 0.483674 \tTraining acc: 0.892188 \tTest acc: 0.868750\tTraining f1: 0.651704 \tTest f1: 0.464883\tTraining auc: 0.827203 \tTest auc: 0.590185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:39<00:16,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 14 \tTraining Loss: 0.388131 \tTest Loss: 0.532437 \tTraining acc: 0.893437 \tTest acc: 0.868750\tTraining f1: 0.625294 \tTest f1: 0.464883\tTraining auc: 0.844650 \tTest auc: 0.523381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:42<00:13,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 15 \tTraining Loss: 0.370929 \tTest Loss: 0.502135 \tTraining acc: 0.901875 \tTest acc: 0.868750\tTraining f1: 0.720416 \tTest f1: 0.464883\tTraining auc: 0.846259 \tTest auc: 0.579394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:44<00:10,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 16 \tTraining Loss: 0.400861 \tTest Loss: 0.657524 \tTraining acc: 0.896250 \tTest acc: 0.868750\tTraining f1: 0.646326 \tTest f1: 0.464883\tTraining auc: 0.808431 \tTest auc: 0.478845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:47<00:07,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 17 \tTraining Loss: 0.462927 \tTest Loss: 0.555765 \tTraining acc: 0.894375 \tTest acc: 0.868750\tTraining f1: 0.646259 \tTest f1: 0.464883\tTraining auc: 0.831617 \tTest auc: 0.547619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:49<00:05,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 18 \tTraining Loss: 0.411533 \tTest Loss: 0.528039 \tTraining acc: 0.902500 \tTest acc: 0.868750\tTraining f1: 0.708743 \tTest f1: 0.464883\tTraining auc: 0.874455 \tTest auc: 0.553015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:52<00:02,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 19 \tTraining Loss: 0.405418 \tTest Loss: 0.925310 \tTraining acc: 0.876563 \tTest acc: 0.868750\tTraining f1: 0.692784 \tTest f1: 0.464883\tTraining auc: 0.790579 \tTest auc: 0.428058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:55<00:00,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 20 \tTraining Loss: 0.500512 \tTest Loss: 0.522796 \tTraining acc: 0.897500 \tTest acc: 0.868750\tTraining f1: 0.661465 \tTest f1: 0.464883\tTraining auc: 0.854706 \tTest auc: 0.562008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=7680, output_size=1)\n",
        "# Define hyperparameters\n",
        "n_epochs = 20\n",
        "lr = 1e-5\n",
        "batch_size = 32\n",
        "weight_decay = 0\n",
        "train_model(model, train_loader, test_loader, lr, weight_decay, n_epochs, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling"
      ],
      "metadata": {
        "id": "vdjUjKsiG6aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_vectors_train = df_train['tensor'].values\n",
        "data_vectors_train_0 = [data_vectors_train[i] for i in range(len(data_vectors_train)) if labels_train[i] == 0]\n",
        "majority_len = len(data_vectors_train_0)\n",
        "data_vectors_train_1 = [data_vectors_train[i] for i in range(len(data_vectors_train)) if labels_train[i] == 1]\n",
        "data_vectors_train_1_os = random.choices(data_vectors_train_1, k=majority_len)\n",
        "data_vectors_train_os = data_vectors_train_0 + data_vectors_train_1_os\n",
        "labels_train_os = np.concatenate((np.zeros(majority_len),np.ones(majority_len)), axis=None).astype('int64')\n",
        "train_data_os = TrainData(data_vectors_train_os, labels_train_os)\n",
        "train_loader = torch.utils.data.DataLoader(train_data_os, batch_size=32, shuffle=True)\n",
        "# data_vectors_test = df_test['tensor'].values"
      ],
      "metadata": {
        "id": "JUPjRTB-G8Ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "71c53c20-67f4-4690-973d-0ba3a0377967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1f4c90658d82>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_vectors_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tensor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_vectors_train_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmajority_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_vectors_train_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_vectors_train_1_os\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajority_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-1f4c90658d82>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_vectors_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tensor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_vectors_train_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmajority_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_vectors_train_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_vectors_train_1_os\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectors_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajority_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=7680, output_size=1)\n",
        "# Define hyperparameters\n",
        "n_epochs = 20\n",
        "lr = 1e-4\n",
        "batch_size = 32\n",
        "weight_decay = 0\n",
        "train_model(model, train_loader, test_loader, lr, weight_decay, n_epochs, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80uNJ8orHRub",
        "outputId": "53902355-3467-4111-df3f-9799146b6ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:04<01:19,  4.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 \tTraining Loss: 9.467683 \tTest Loss: 9.291238 \tTraining acc: 0.606746 \tTest acc: 0.868750\tTraining f1: 0.595634 \tTest f1: 0.464883\tTraining auc: 0.651398 \tTest auc: 0.610740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:09<01:23,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 \tTraining Loss: 4.810053 \tTest Loss: 7.016119 \tTraining acc: 0.646215 \tTest acc: 0.868750\tTraining f1: 0.644420 \tTest f1: 0.464883\tTraining auc: 0.697581 \tTest auc: 0.570658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:13<01:15,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3 \tTraining Loss: 3.558314 \tTest Loss: 3.071363 \tTraining acc: 0.620919 \tTest acc: 0.868750\tTraining f1: 0.597334 \tTest f1: 0.464883\tTraining auc: 0.694566 \tTest auc: 0.625557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:17<01:09,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4 \tTraining Loss: 3.637872 \tTest Loss: 4.408882 \tTraining acc: 0.706136 \tTest acc: 0.868750\tTraining f1: 0.701616 \tTest f1: 0.464883\tTraining auc: 0.801548 \tTest auc: 0.615450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:22<01:08,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5 \tTraining Loss: 3.083592 \tTest Loss: 4.112598 \tTraining acc: 0.751346 \tTest acc: 0.868750\tTraining f1: 0.746736 \tTest f1: 0.464883\tTraining auc: 0.817773 \tTest auc: 0.598493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:26<01:03,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 \tTraining Loss: 2.917485 \tTest Loss: 3.553485 \tTraining acc: 0.698780 \tTest acc: 0.868750\tTraining f1: 0.697381 \tTest f1: 0.464883\tTraining auc: 0.746953 \tTest auc: 0.597936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:30<00:56,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 \tTraining Loss: 2.543442 \tTest Loss: 3.165892 \tTraining acc: 0.786329 \tTest acc: 0.868750\tTraining f1: 0.786329 \tTest f1: 0.464883\tTraining auc: 0.852871 \tTest auc: 0.583162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:36<00:56,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 \tTraining Loss: 2.603999 \tTest Loss: 2.967119 \tTraining acc: 0.650879 \tTest acc: 0.868750\tTraining f1: 0.624553 \tTest f1: 0.464883\tTraining auc: 0.802977 \tTest auc: 0.632151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:40<00:49,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 9 \tTraining Loss: 2.168548 \tTest Loss: 3.305994 \tTraining acc: 0.776642 \tTest acc: 0.868750\tTraining f1: 0.776518 \tTest f1: 0.464883\tTraining auc: 0.852985 \tTest auc: 0.582819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:45<00:46,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10 \tTraining Loss: 1.759596 \tTest Loss: 3.324629 \tTraining acc: 0.787047 \tTest acc: 0.868750\tTraining f1: 0.786797 \tTest f1: 0.464883\tTraining auc: 0.855527 \tTest auc: 0.588215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:49<00:40,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 11 \tTraining Loss: 1.845957 \tTest Loss: 3.034169 \tTraining acc: 0.784535 \tTest acc: 0.868750\tTraining f1: 0.783922 \tTest f1: 0.464883\tTraining auc: 0.863459 \tTest auc: 0.535886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:53<00:34,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 12 \tTraining Loss: 1.536507 \tTest Loss: 3.007930 \tTraining acc: 0.759598 \tTest acc: 0.868750\tTraining f1: 0.758021 \tTest f1: 0.464883\tTraining auc: 0.819086 \tTest auc: 0.561665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:57<00:29,  4.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 13 \tTraining Loss: 0.971123 \tTest Loss: 2.222860 \tTraining acc: 0.686222 \tTest acc: 0.868750\tTraining f1: 0.665191 \tTest f1: 0.464883\tTraining auc: 0.861506 \tTest auc: 0.601233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [01:02<00:26,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 14 \tTraining Loss: 0.893737 \tTest Loss: 0.794759 \tTraining acc: 0.824901 \tTest acc: 0.868750\tTraining f1: 0.822958 \tTest f1: 0.464883\tTraining auc: 0.915030 \tTest auc: 0.502484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [01:06<00:21,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 15 \tTraining Loss: 0.747108 \tTest Loss: 0.967497 \tTraining acc: 0.788841 \tTest acc: 0.868750\tTraining f1: 0.785042 \tTest f1: 0.464883\tTraining auc: 0.900324 \tTest auc: 0.585260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [01:10<00:17,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 16 \tTraining Loss: 0.642263 \tTest Loss: 1.144829 \tTraining acc: 0.874955 \tTest acc: 0.868750\tTraining f1: 0.874697 \tTest f1: 0.464883\tTraining auc: 0.937382 \tTest auc: 0.562050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [01:14<00:12,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 17 \tTraining Loss: 0.390227 \tTest Loss: 1.315994 \tTraining acc: 0.842124 \tTest acc: 0.868750\tTraining f1: 0.841347 \tTest f1: 0.464883\tTraining auc: 0.905096 \tTest auc: 0.580207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [01:18<00:08,  4.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 18 \tTraining Loss: 0.417962 \tTest Loss: 1.133682 \tTraining acc: 0.826337 \tTest acc: 0.868750\tTraining f1: 0.822628 \tTest f1: 0.464883\tTraining auc: 0.915864 \tTest auc: 0.556012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [01:22<00:04,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 19 \tTraining Loss: 0.386246 \tTest Loss: 0.695950 \tTraining acc: 0.849839 \tTest acc: 0.868750\tTraining f1: 0.848795 \tTest f1: 0.464883\tTraining auc: 0.949219 \tTest auc: 0.510106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:27<00:00,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 20 \tTraining Loss: 0.309922 \tTest Loss: 0.730590 \tTraining acc: 0.881414 \tTest acc: 0.868750\tTraining f1: 0.880700 \tTest f1: 0.464883\tTraining auc: 0.969668 \tTest auc: 0.505824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forests"
      ],
      "metadata": {
        "id": "N85_zurAbNWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "NDz702ZPhxGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_vectors_train = df_train['tensor'].values\n",
        "data_vectors_train_0 = [data_vectors_train[i] for i in range(len(data_vectors_train)) if labels_train[i] == 0]\n",
        "majority_len = len(data_vectors_train_0)\n",
        "data_vectors_train_1 = [data_vectors_train[i] for i in range(len(data_vectors_train)) if labels_train[i] == 1]\n",
        "data_vectors_train_1_os = random.choices(data_vectors_train_1, k=majority_len)\n",
        "data_vectors_train_os = data_vectors_train_0 + data_vectors_train_1_os\n",
        "labels_train_os = np.concatenate((np.zeros(majority_len),np.ones(majority_len)), axis=None).astype('int64')\n",
        "train_data_os = TrainData(data_vectors_train_os, labels_train_os)\n",
        "train_loader = torch.utils.data.DataLoader(train_data_os, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "IQVZDmBNpxoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequence(df_train['tensor'],batch_first=True)"
      ],
      "metadata": {
        "id": "IBbJfwqkk7EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pad_sequence(df_test['tensor'], batch_first=True)"
      ],
      "metadata": {
        "id": "AT88KOsWsttn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.size())\n",
        "print(x_test.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZXlhufmmlYE",
        "outputId": "3c9509ca-6f52-4b36-c841-3d5df4734d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3200, 60330])\n",
            "torch.Size([320, 23130])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.zeros([len(x_train),len(max(x_train,key = lambda x: len(x)))])\n",
        "for i,j in enumerate(x_train):\n",
        "        a[i][0:len(j)] = j\n",
        "a = a[:,0:x_test.size(1)]"
      ],
      "metadata": {
        "id": "nEhlAJgLuJcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert list of lists with different lengths to a numpy array\n",
        "b = np.zeros([len(x_test),len(max(x_train,key = lambda x: len(x)))])\n",
        "for i,j in enumerate(x_test):\n",
        "        b[i][0:len(j)] = j\n",
        "b = b[:,0:x_test.size(1)]"
      ],
      "metadata": {
        "id": "mSrW92CrsMeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.size(b,axis=0))\n",
        "print(np.size(b,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6GYD0ETtlzE",
        "outputId": "90239cb6-fe13-4433-a463-6c5720d56ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n",
            "23130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=300,max_depth=10)\n",
        "rf.fit(a, df_train['y_true'])"
      ],
      "metadata": {
        "id": "3oY0VqlPi1KU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "c4b54d4e-2423-474f-e8b6-5db32aab39de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, n_estimators=300)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=300)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(b)\n",
        "y_pred_prob = rf.predict_proba(b)\n",
        "print(len(y_pred))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(df_test['y_true'], y_pred_prob[:,1])\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print('Random forests auc is', auc)\n",
        "print('Random forests f1 is', f1_score(df_test['y_true'], y_pred, average='macro'))\n",
        "print('Random forests accuracy is',accuracy_score(df_test['y_true'], y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loy9U89miTy7",
        "outputId": "bf00f1b9-f6c5-49f0-d841-e4972731279c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n",
            "Random forests auc is 0.6220452209660843\n",
            "Random forests f1 is 0.46488294314381273\n",
            "Random forests accuracy is 0.86875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "9ChxCsGWxxPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(probability=True)\n",
        "svm.fit(a, df_train['y_true'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "FQdtwpXDbT1Y",
        "outputId": "5eb0ca8c-b9a3-4ce3-8061-0f53c049c74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(b)\n",
        "y_pred_prob = svm.predict_proba(b)\n",
        "print(len(y_pred))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(df_test['y_true'], y_pred_prob[:,1])\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print('SVM auc is', auc)\n",
        "print('SVM f1 is', f1_score(df_test['y_true'], y_pred, average='macro'))\n",
        "print('SVM accuracy is',accuracy_score(df_test['y_true'], y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxsYE9vqx-1Q",
        "outputId": "973cb671-6a47-4659-dba3-13e392a24096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n",
            "SVM auc is 0.6252141144227474\n",
            "SVM f1 is 0.4889174554945269\n",
            "SVM accuracy is 0.871875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XG-boost"
      ],
      "metadata": {
        "id": "vL5I0wVebTRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "YYI7hxrlbXf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(\n",
        "    n_estimators = 300,\n",
        "    max_depth = 10,\n",
        ")\n",
        "model.fit(a,df_train['y_true'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "VHQbxousyaKh",
        "outputId": "acde4af9-4cb4-4cdc-db39-2164d38a5206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict_proba(b)\n",
        "y_pred = model.predict(b)\n",
        "print(len(y_pred))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(df_test['y_true'], y_pred_prob[:,1])\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print('XGboost auc is', auc)\n",
        "print('XGboost f1 is', f1_score(df_test['y_true'], y_pred, average='macro'))\n",
        "print('XGboost accuracy is',accuracy_score(df_test['y_true'], y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygHIOLUzCPT",
        "outputId": "4f68b93a-a6a0-4492-f920-7d3e328ed746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n",
            "XGboost auc is 0.5969510106200754\n",
            "XGboost f1 is 0.4612794612794613\n",
            "XGboost accuracy is 0.85625\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}